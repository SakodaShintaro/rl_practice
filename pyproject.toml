[project]
name = "rl-practice"
version = "0.1.0"
requires-python = ">=3.10,<3.11"
dependencies = [
    "gymnasium[box2d]",
    "gymnasium[mujoco]",
    "gymnasium[other]",
    "wandb",
    "tyro",
    "stable-baselines3",
    "timm",
    "opencv-python",
    "diffusers",
    "accelerate",
    "hl_gauss_pytorch",
    "wheel",
    "packaging",
    "num2words",
    "imageio[ffmpeg]",
    "minigrid",
    "peft",
    "fschat",
    "sentencepiece",
    "qwen-vl-utils",
    "bitsandbytes",
    "flash-linear-attention",
    "pytesseract",
    "pyautogui",
    "pynput",
    # CUDA拡張パッケージ（プリビルドホイール使用）
    "mamba-ssm",
    "causal-conv1d",
    "flash-attn",
    # PyTorch 2.7系に固定（プリビルドホイールとの互換性のため）
    "torch>=2.7,<2.8",
]

[tool.uv.sources]
causal-conv1d = { url = "https://github.com/Dao-AILab/causal-conv1d/releases/download/v1.5.2/causal_conv1d-1.5.2+cu12torch2.7cxx11abiTRUE-cp310-cp310-linux_x86_64.whl" }
flash-attn = { url = "https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.1/flash_attn-2.8.1+cu12torch2.7cxx11abiTRUE-cp310-cp310-linux_x86_64.whl" }
mamba-ssm = { url = "https://github.com/state-spaces/mamba/releases/download/v2.2.5/mamba_ssm-2.2.5+cu12torch2.6cxx11abiTRUE-cp310-cp310-linux_x86_64.whl" }

[tool.ruff]
line-length = 100

[tool.ruff.lint]
select = ["I"]
extend-ignore = ["ANN", "D"]
ignore = [
    "ARG002",
    "COM812",
    "E501",
    "EM101",
    "PERF102",
    "PTH119",
    "PLR0913",
    "RET504",
    "RSE102",
    "SIM102", "SIM118",
    "UP031",

    "B028",
    "BLE001",
    "D100", "D103", "D104", "D105", "D107", "D205", "D212", "D213",
    "DTZ005",
    "EM102",
    "ERA001",
    "FA100", "FA102",
    "FBT001", "FBT002",
    "G004",
    "INP001",
    "N806", "N812",
    "NPY002",
    "PD901",
    "PLR2004",
    "PLW2901",
    "RET505",
    "RUF003",
    "S101", "S602",
    "T201",
    "TRY003",
]
